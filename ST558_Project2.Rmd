---
title: "ST558 Project 2: Creating predictive models and automating Markdown reports."
author: "Josh Baber & Lan Lin"
date: '2022-07-06'
output: html_document
---

```{r setup, include=FALSE}
#knitr::opts_knit$set(root.dir = 'F:\\Graduate\\NCSU_courses\\ST558\\projects\\Project_2\\OnlineNewsPopularity')
set.seed(558)
```

```{r, include=FALSE}
library(tidyverse)
library(reader)
library(corrplot)
library(caret)
library(elasticnet)
```


Read in the data set
```{r}
# Read in the data set and remove the non-predictive variables 
shares_Data <- read_csv("C:/Users/squas/OneDrive/Desktop/ST 558/Data/OnlineNewsPopularity.csv")[-2:-1]
head(shares_Data)
```

Convert the dummy variables of channels to single categorical variable
```{r}
# create a single variable representing the data channel
channel <- factor(cbind(VALUE = factor(max.col(shares_Data[12:17]), ordered = TRUE)))
levels(channel) <- c( 'Lifestyle', 'Entertainment', 'Business', 'Social Media', 'Tech', 'World')

# Create a new data set using the single variable representing the data channel
shares_Data_chl <- shares_Data %>% select(-starts_with("data_channel")) %>% 
                     mutate(channel) %>% 
                     select(channel, everything())
```

Subset the data to work on the "Lifestyle" data channel 
```{r}
shares_Lifestyle <- shares_Data_chl %>% filter(channel == "Lifestyle")
```

```{r}
# These are the variables we will be using
varcols <- c(2:4, 7, 9:11, 15, 18, 21, 24:32, 38:41, 44, 47, 50:54)
names(shares_Lifestyle)[varcols]
```

```{r}
# Subset lifestyles table into relevant columns
shares_Lifestyle <- shares_Lifestyle[,varcols]
# Split into testing and training
trainIndices <- createDataPartition(shares_Lifestyle$shares, p = 0.7, list = FALSE)
# Create training set
lifestyleTrain <- shares_Lifestyle[trainIndices,]
# Create testing set
lifestyleTest <- shares_Lifestyle[-trainIndices,]
```




```{r}
# Shares by day
# create a single variable representing the data channel
day <- factor(cbind(VALUE = factor(max.col(lifestyleTrain[12:18]), ordered = TRUE)))
levels(day) <- c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday')

# Create a new data set using the single variable representing the data channel
daily_Shares_Data_Lifestyle <- lifestyleTrain %>% 
  select(-starts_with("weekday_is")) %>% 
  mutate(day) %>% 
  select(day, everything())
daily_Shares_Data_Lifestyle %>% 
  group_by(day) %>%
  summarize(avgShares = mean(shares), medShares = median(shares), minShares = min(shares), 
            maxShares = max(shares), sdShares = sd(shares))
```

```{r}
# Bar chart of mean shares  
daily_Means <- daily_Shares_Data_Lifestyle %>% 
  group_by(day) %>%
  summarize(avgShares = mean(shares))
ggplot(daily_Means, aes(x = day, y = avgShares)) + 
  geom_line(aes(group = 1), color = "blue") + geom_point() + 
  labs(title = "Average Shares Per Day") + 
  xlab("Day of Week") + ylab("Mean Shares")
```

```{r}
# Counts by day
table(daily_Shares_Data_Lifestyle$day)
```

```{r}
lifestyleTrain %>% 
  summarize(avgLinks = mean(num_hrefs), avgImages = mean(num_imgs), avgVideos = mean(num_videos))
```

```{r}
ggplot(lifestyleTrain, aes(x = shares)) + geom_boxplot() + labs(title = "Boxplot of Shares") + 
  xlab("Number of Shares")
```

```{r}
ggplot(lifestyleTrain, aes(x = shares)) + geom_boxplot(outlier.shape = NA) +
  scale_x_continuous(limits = c(min(lifestyleTrain$shares), 2*IQR(lifestyleTrain$shares))) + 
  labs(title = "Boxplot of Shares (Outliers Removed)") + xlab("Number of Shares")
```


```{r}
ggplot(data = lifestyleTrain, aes(x = n_tokens_content, y = shares)) + 
  geom_point(aes(col = factor(is_weekend))) + 
  labs(title = "Word Count and Shares, Colored by Weekend/Weekday") + 
  xlab("Word Count") + ylab("Number of Shares") + 
  scale_color_discrete(name = " ", labels = c("Weekday", "Weekend"))
```

```{r}
ggplot(data = lifestyleTrain, aes(x = n_tokens_content, y = shares)) + 
  geom_point(aes(col = factor(is_weekend))) + 
  labs(title = " Zoomed In Word Count and Shares, Colored by Weekend/Weekday") + 
  xlab("Word Count") + ylab("Number of Shares") + 
  scale_color_discrete(name = " ", labels = c("Weekday", "Weekend")) + 
  coord_cartesian(xlim = c(0, 2000), ylim = c(0, 40000))
```

```{r}
# Remove is_weekend variable keep day column
dailyLifestyleTrain <- daily_Shares_Data_Lifestyle %>% select(-is_weekend)
day <- factor(cbind(VALUE = factor(max.col(lifestyleTest[12:18]), ordered = TRUE)))
levels(day) <- c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday')

# Create a new data set using the single variable representing the data channel
daily_Shares_Test_Lifestyle <- lifestyleTest %>% 
  select(-starts_with("weekday_is")) %>% 
  mutate(day) %>% 
  select(day, everything())
dailyLifestyleTest <- daily_Shares_Test_Lifestyle %>% select(-is_weekend)
```

```{r}
# Linear Regression Model using LASSO
lassoFit <- train(shares ~ ., data = dailyLifestyleTrain, method = "lasso",
                  preProcess = c("center", "scale"))
```

```{r}
predslinear <- predict(lassoFit, newdata = dailyLifestyleTest)
postResample(predslinear, obs = dailyLifestyleTest$shares)
```

```{r}
# Values of n.trees
nTrees <- c(10, 50, 100, 200)
# Values of interaction.depth
intDepth <- c(1, 2, 3, 4)
# Value of shrinkage
shrink <- c(0.001, 0.05, 0.1, 0.5)
# Value of n.minobsinnode
nodeMinN <- c(5, 10, 15, 20)
# Fit the boosted tree model on the training data
lifestyleBoost <- train(shares ~ ., data = lifestyleTrain, method = "gbm",
                        # Perform 5 fold cross validation repeated 3 times
                        trControl = trainControl(method = "cv", number = 10),
                        # Standardize the data, hide output with verborse = FALSE
                        preProcess = c("center", "scale"), verbose = FALSE,
                        # Check all possible combinations of n.trees, interaction.depth,
                        # shrinkage, and n.minobsinnode tuning parameters
                        tuneGrid = expand.grid(n.trees = nTrees, interaction.depth = intDepth,
                                               shrinkage = shrink, n.minobsinnode = nodeMinN))
```



```{r}
# Generate confusion matrix to assess model fit on testing data
predsBoost <- predict(lifestyleBoost, newdata = lifestyleTest)
postResample(predsBoost, obs = lifestyleTest$shares)[[1]]
```

```{r}
bestModel <- function(linearmodel, boostedmodel){
  predslinear <- predict(linearmodel, newdata = lifestyleTest)
  predsboost <- predict(boostedmodel, newdata = lifestyleTest)
  RMSElinear <- postResample(predslinear, obs = lifestyleTest$shares)[[1]]
  RMSEboost <- postResample(predsboost, obs = lifestyleTest$shares)[[1]]
  bestRMSE <- min(c(RMSElinear, RMSEboost))
  if(bestRMSE == RMSElinear){
    print("The Linear Model Had the Lowest RMSE")
  }
  else if(bestRMSE == RMSEboost){
    print("The Boosted Tree Model Had the Lowest RMSE")
  }
}
```

```{r}
bestModel(linearmodel = lassoFit, boostedmodel = lifestyleBoost)
```

